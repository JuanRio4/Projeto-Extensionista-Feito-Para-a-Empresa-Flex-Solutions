{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 482,
          "sourceType": "datasetVersion",
          "datasetId": 228
        },
        {
          "sourceId": 2437,
          "sourceType": "datasetVersion",
          "datasetId": 1233
        },
        {
          "sourceId": 5125,
          "sourceType": "datasetVersion",
          "datasetId": 3086
        },
        {
          "sourceId": 37484,
          "sourceType": "datasetVersion",
          "datasetId": 29414
        },
        {
          "sourceId": 122455,
          "sourceType": "datasetVersion",
          "datasetId": 63117
        },
        {
          "sourceId": 426002,
          "sourceType": "datasetVersion",
          "datasetId": 191041
        },
        {
          "sourceId": 2139598,
          "sourceType": "datasetVersion",
          "datasetId": 1252776
        },
        {
          "sourceId": 7608018,
          "sourceType": "datasetVersion",
          "datasetId": 4429813
        }
      ],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "uciml_pima_indians_diabetes_database_path = kagglehub.dataset_download('uciml/pima-indians-diabetes-database')\n",
        "mkachuee_bloodpressuredataset_path = kagglehub.dataset_download('mkachuee/BloodPressureDataset')\n",
        "mkachuee_noninvasivebp_path = kagglehub.dataset_download('mkachuee/noninvasivebp')\n",
        "shayanfazeli_heartbeat_path = kagglehub.dataset_download('shayanfazeli/heartbeat')\n",
        "harunshimanto_epileptic_seizure_recognition_path = kagglehub.dataset_download('harunshimanto/epileptic-seizure-recognition')\n",
        "qiriro_stress_path = kagglehub.dataset_download('qiriro/stress')\n",
        "adibadea_chbmitseizuredataset_path = kagglehub.dataset_download('adibadea/chbmitseizuredataset')\n",
        "abdallahwagih_mit_bih_arrhythmia_database_path = kagglehub.dataset_download('abdallahwagih/mit-bih-arrhythmia-database')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3rsFOitugEs",
        "outputId": "3b367306-5668-4520-d0e2-adf539a7256e"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'pima-indians-diabetes-database' dataset.\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mkachuee/BloodPressureDataset?dataset_version_number=5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.60G/4.60G [00:56<00:00, 86.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mkachuee/noninvasivebp?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76.9M/76.9M [00:00<00:00, 177MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'heartbeat' dataset.\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/harunshimanto/epileptic-seizure-recognition?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.77M/2.77M [00:00<00:00, 112MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/qiriro/stress?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.24G/5.24G [00:53<00:00, 106MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/adibadea/chbmitseizuredataset?dataset_version_number=8...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 635M/635M [00:05<00:00, 130MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/abdallahwagih/mit-bih-arrhythmia-database?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73.4M/73.4M [00:01<00:00, 56.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Setup with Dataset Verification\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVR, SVC\n",
        "from sklearn.metrics import classification_report, mean_absolute_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "def load_or_simulate_dataset(dataset_name, default_rows=1000):\n",
        "    \"\"\"Try loading dataset or simulate reasonable defaults\"\"\"\n",
        "    try:\n",
        "        if dataset_name == \"diabetes\":\n",
        "            return pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\n",
        "        elif dataset_name == \"arrhythmia\":\n",
        "            return pd.read_csv('/kaggle/input/mitbih-arrhythmia-database/mitbih_train.csv', header=None)\n",
        "        elif dataset_name == \"stress\":\n",
        "            return pd.read_csv('/kaggle/input/stress-detection-in-employees/Stress.csv')  # Common filename\n",
        "        else:\n",
        "            raise FileNotFoundError\n",
        "    except:\n",
        "        print(f\"⚠️ {dataset_name} dataset not found - simulating data\")\n",
        "        return simulate_dataset(dataset_name, default_rows)\n",
        "\n",
        "def simulate_dataset(dataset_name, rows):\n",
        "    \"\"\"Create realistic synthetic data\"\"\"\n",
        "    if dataset_name == \"diabetes\":\n",
        "        data = pd.DataFrame({\n",
        "            'Pregnancies': np.random.randint(0, 10, rows),\n",
        "            'Glucose': np.random.normal(120, 30, rows).clip(70, 200),\n",
        "            'BloodPressure': np.random.normal(70, 15, rows).clip(40, 100),\n",
        "            'SkinThickness': np.random.normal(20, 5, rows),\n",
        "            'Insulin': np.random.normal(100, 50, rows),\n",
        "            'BMI': np.random.normal(30, 5, rows),\n",
        "            'DiabetesPedigreeFunction': np.random.uniform(0.1, 1.5, rows),\n",
        "            'Age': np.random.randint(20, 70, rows),\n",
        "            'Outcome': np.random.binomial(1, 0.3, rows)\n",
        "        })\n",
        "        data['hrv'] = np.where(data['Outcome'] == 1,\n",
        "                             np.random.normal(50, 5, rows),\n",
        "                             np.random.normal(70, 5, rows))\n",
        "\n",
        "    elif dataset_name == \"arrhythmia\":\n",
        "        data = pd.DataFrame(np.random.randn(rows, 187))  # MIT-BIH has 187 timesteps\n",
        "        data['label'] = np.random.randint(0, 5, rows)  # 5 classes\n",
        "\n",
        "    elif dataset_name == \"stress\":\n",
        "        data = pd.DataFrame({\n",
        "            'snoring_range': np.random.normal(50, 10, rows),\n",
        "            'respiration_rate': np.random.normal(20, 3, rows),\n",
        "            'body_temp': np.random.normal(98, 1, rows),\n",
        "            'limb_movement': np.random.normal(5, 2, rows),\n",
        "            'blood_oxygen': np.random.normal(97, 2, rows),\n",
        "            'eye_movement': np.random.normal(5, 2, rows),\n",
        "            'sleeping_hours': np.random.normal(6, 1, rows),\n",
        "            'heart_rate': np.random.normal(70, 10, rows),\n",
        "            'stress': np.random.binomial(1, 0.25, rows)\n",
        "        })\n",
        "        data['gsr'] = np.where(data['stress'] == 1,\n",
        "                             np.random.normal(8, 1, rows),\n",
        "                             np.random.normal(4, 1, rows))\n",
        "\n",
        "    return data\n",
        "\n",
        "# Load or simulate all datasets\n",
        "diabetes_data = load_or_simulate_dataset(\"diabetes\")\n",
        "arrhythmia_data = load_or_simulate_dataset(\"arrhythmia\")\n",
        "stress_data = load_or_simulate_dataset(\"stress\")\n",
        "\n",
        "# Verify datasets\n",
        "print(\"✅ Loaded datasets:\")\n",
        "print(f\"- Diabetes: {diabetes_data.shape}\")\n",
        "print(f\"- Arrhythmia: {arrhythmia_data.shape}\")\n",
        "print(f\"- Stress: {stress_data.shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX2o9nlOugEx",
        "outputId": "2f89f6c6-f1aa-4fb3-c5dd-cf7803651118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ arrhythmia dataset not found - simulating data\n",
            "⚠️ stress dataset not found - simulating data\n",
            "✅ Loaded datasets:\n",
            "- Diabetes: (768, 9)\n",
            "- Arrhythmia: (1000, 188)\n",
            "- Stress: (1000, 10)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Diabetes Model with HRV Simulation\n",
        "if 'hrv' not in diabetes_data.columns:\n",
        "    diabetes_data['hrv'] = np.where(diabetes_data['Outcome'] == 1,\n",
        "                                  np.random.normal(50, 5, len(diabetes_data)),\n",
        "                                  np.random.normal(70, 5, len(diabetes_data)))\n",
        "\n",
        "X_dia = diabetes_data[['Glucose', 'BMI', 'Age', 'hrv']]\n",
        "y_dia = diabetes_data['Outcome']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_dia, y_dia, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "rf_dia = RandomForestClassifier(n_estimators=100)\n",
        "rf_dia.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Diabetes Model Performance:\")\n",
        "print(classification_report(y_test, rf_dia.predict(X_test_scaled)))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YGmoFf-ugEz",
        "outputId": "5955b61c-fe93-43b1-eb54-6cfc5dd79180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diabetes Model Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99        99\n",
            "           1       0.98      1.00      0.99        55\n",
            "\n",
            "    accuracy                           0.99       154\n",
            "   macro avg       0.99      0.99      0.99       154\n",
            "weighted avg       0.99      0.99      0.99       154\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Arrhythmia Detection (Works with MIT-BIH or simulated)\n",
        "arrhythmia_data.columns = [f'ecg_{i}' for i in range(arrhythmia_data.shape[1]-1)] + ['label']\n",
        "\n",
        "# Simple version for Kaggle (full LSTM would need more preprocessing)\n",
        "X_arr = arrhythmia_data.iloc[:, :-1]\n",
        "y_arr = arrhythmia_data['label']\n",
        "\n",
        "# Binary classification (normal vs abnormal)\n",
        "y_arr_binary = (y_arr > 0).astype(int)\n",
        "\n",
        "rf_arr = RandomForestClassifier()\n",
        "rf_arr.fit(X_arr, y_arr_binary)\n",
        "\n",
        "print(\"Arrhythmia Detection (Binary):\")\n",
        "print(classification_report(y_arr_binary, rf_arr.predict(X_arr)))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgMCnPjPugE1",
        "outputId": "dd44e535-fa58-493b-c24d-3f745d2f95bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arrhythmia Detection (Binary):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       201\n",
            "           1       1.00      1.00      1.00       799\n",
            "\n",
            "    accuracy                           1.00      1000\n",
            "   macro avg       1.00      1.00      1.00      1000\n",
            "weighted avg       1.00      1.00      1.00      1000\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Stress Detection with GSR Simulation\n",
        "if 'gsr' not in stress_data.columns:\n",
        "    stress_data['gsr'] = np.where(stress_data['stress'] == 1,\n",
        "                                np.random.normal(8, 1, len(stress_data)),\n",
        "                                np.random.normal(4, 1, len(stress_data)))\n",
        "\n",
        "X_stress = stress_data[['gsr', 'heart_rate', 'body_temp']]\n",
        "y_stress = stress_data['stress']\n",
        "\n",
        "svm_stress = SVC(probability=True)\n",
        "svm_stress.fit(X_stress, y_stress)\n",
        "\n",
        "print(\"Stress Detection Performance:\")\n",
        "print(classification_report(y_stress, svm_stress.predict(X_stress)))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBIw89c4ugE2",
        "outputId": "20c82ef7-a4a6-47e3-9357-aff8a02f2156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stress Detection Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94       750\n",
            "           1       0.99      0.62      0.76       250\n",
            "\n",
            "    accuracy                           0.90      1000\n",
            "   macro avg       0.94      0.81      0.85      1000\n",
            "weighted avg       0.91      0.90      0.89      1000\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Blood Pressure Simulation (since dataset was missing)\n",
        "# Create synthetic BP data using known physiological relationships\n",
        "bp_data = pd.DataFrame({\n",
        "    'age': np.random.randint(20, 80, 500),\n",
        "    'bmi': np.random.normal(25, 5, 500).clip(18, 40),\n",
        "    'heart_rate': np.random.normal(70, 10, 500).clip(50, 100),\n",
        "    'ptt': np.random.normal(0.15, 0.03, 500)  # Pulse Transit Time\n",
        "})\n",
        "bp_data['sbp'] = 110 + 0.5*bp_data['age'] + 0.3*bp_data['bmi'] - 0.2*bp_data['ptt']*1000\n",
        "bp_data['dbp'] = 70 + 0.3*bp_data['age'] + 0.2*bp_data['bmi'] - 0.1*bp_data['ptt']*1000\n",
        "\n",
        "# Add simulated ECG quality\n",
        "bp_data['ecg_quality'] = np.random.uniform(0.8, 1.0, len(bp_data))\n",
        "\n",
        "# Train BP model\n",
        "svr_sbp = SVR()\n",
        "svr_sbp.fit(bp_data[['ptt', 'ecg_quality']], bp_data['sbp'])\n",
        "\n",
        "print(\"BP Model MAE:\", mean_absolute_error(\n",
        "    bp_data['sbp'],\n",
        "    svr_sbp.predict(bp_data[['ptt', 'ecg_quality']])\n",
        "))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucKkCYBkugE3",
        "outputId": "78f42e56-9a79-4723-b860-2ab241c7a9e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BP Model MAE: 8.616784912623283\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Export for Smartwatch Integration\n",
        "import joblib\n",
        "\n",
        "joblib.dump({\n",
        "    'diabetes_scaler': scaler,\n",
        "    'diabetes_model': rf_dia,\n",
        "    'arrhythmia_model': rf_arr,\n",
        "    'stress_model': svm_stress,\n",
        "    'bp_model': svr_sbp\n",
        "}, 'health_models.pkl')\n",
        "\n",
        "print(\"✅ All models exported successfully!\")"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwlDNukdugE3",
        "outputId": "7983f178-e530-4d8e-e4fb-413693e40392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All models exported successfully!\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula para Otimização com Algoritmo Genético\n",
        "\n",
        "# Instale a biblioteca se precisar\n",
        "#!pip install deap\n",
        "\n",
        "import random\n",
        "from deap import base, creator, tools, algorithms\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# --- Passo 1: Configurar o Algoritmo Genético ---\n",
        "# Criar a função de aptidão: queremos maximizar a precisão\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "\n",
        "# Definir os hiperparâmetros que o algoritmo irá otimizar\n",
        "# Exemplo para o Random Forest de diabetes:\n",
        "toolbox.register(\"attr_n_estimators\", random.randint, 50, 200)\n",
        "toolbox.register(\"attr_max_depth\", random.randint, 5, 20)\n",
        "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
        "                 (toolbox.attr_n_estimators, toolbox.attr_max_depth), n=1)\n",
        "\n",
        "# Definir a população de indivíduos\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "# Definir a função de avaliação (fitness)\n",
        "def evaluate_diabetes(individual):\n",
        "    n_estimators = individual[0]\n",
        "    max_depth = individual[1]\n",
        "\n",
        "    # Criar e treinar o modelo com os hiperparâmetros\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Avaliar o modelo usando validação cruzada\n",
        "    try:\n",
        "        score = cross_val_score(model, X_dia, y_dia, cv=5, scoring='accuracy').mean()\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na avaliação: {e}\")\n",
        "        score = 0\n",
        "    return (score,)\n",
        "\n",
        "toolbox.register(\"evaluate\", evaluate_diabetes)\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)  # Crossover\n",
        "toolbox.register(\"mutate\", tools.mutUniformInt, low=[50, 5], up=[200, 20], indpb=0.1)  # Mutação\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)  # Seleção\n",
        "\n",
        "# --- Passo 2: Executar o Algoritmo Genético ---\n",
        "print(\"Iniciando a otimização dos hiperparâmetros do modelo de diabetes...\")\n",
        "\n",
        "pop = toolbox.population(n=20)\n",
        "hof = tools.HallOfFame(1)  # Armazenar o melhor indivíduo\n",
        "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "stats.register(\"avg\", np.mean)\n",
        "stats.register(\"min\", np.min)\n",
        "stats.register(\"max\", np.max)\n",
        "\n",
        "algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=20, stats=stats, halloffame=hof, verbose=True)\n",
        "\n",
        "# --- Passo 3: Exibir o Melhor Resultado ---\n",
        "print(\"\\n--- Resultados da Otimização do Modelo de Diabetes ---\")\n",
        "best_individual = hof[0]\n",
        "best_score = best_individual.fitness.values[0]\n",
        "\n",
        "print(f\"Melhores hiperparâmetros: n_estimators={best_individual[0]}, max_depth={best_individual[1]}\")\n",
        "print(f\"Precisão de Validação Cruzada do melhor modelo: {best_score:.4f}\")\n",
        "\n",
        "# Exemplo de uso do melhor modelo\n",
        "best_rf_dia = RandomForestClassifier(\n",
        "    n_estimators=best_individual[0],\n",
        "    max_depth=best_individual[1],\n",
        "    random_state=42\n",
        ")\n",
        "best_rf_dia.fit(X_dia, y_dia)\n",
        "print(\"\\nDesempenho final do modelo otimizado:\")\n",
        "print(classification_report(y_test, best_rf_dia.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi_6nfN9w2ph",
        "outputId": "f9321875-cdc1-423d-eaa1-57cfa6bbb673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.4.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from deap) (2.0.2)\n",
            "Downloading deap-1.4.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/136.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.0/136.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deap\n",
            "Successfully installed deap-1.4.3\n",
            "Iniciando a otimização dos hiperparâmetros do modelo de diabetes...\n",
            "gen\tnevals\tavg     \tmin     \tmax     \n",
            "0  \t20    \t0.988286\t0.986988\t0.989585\n",
            "1  \t11    \t0.988351\t0.988286\t0.989585\n",
            "2  \t10    \t0.988351\t0.988286\t0.989585\n",
            "3  \t12    \t0.988221\t0.986988\t0.988286\n",
            "4  \t14    \t0.988221\t0.986988\t0.988286\n",
            "5  \t9     \t0.988286\t0.988286\t0.988286\n",
            "6  \t6     \t0.988286\t0.988286\t0.988286\n",
            "7  \t17    \t0.988156\t0.986988\t0.988286\n",
            "8  \t12    \t0.988286\t0.988286\t0.988286\n",
            "9  \t13    \t0.988286\t0.988286\t0.988286\n",
            "10 \t8     \t0.988286\t0.988286\t0.988286\n",
            "11 \t5     \t0.988286\t0.988286\t0.988286\n",
            "12 \t14    \t0.988286\t0.988286\t0.988286\n",
            "13 \t9     \t0.988286\t0.988286\t0.988286\n",
            "14 \t4     \t0.988286\t0.988286\t0.988286\n",
            "15 \t14    \t0.988286\t0.988286\t0.988286\n",
            "16 \t10    \t0.988286\t0.988286\t0.988286\n",
            "17 \t14    \t0.988286\t0.988286\t0.988286\n",
            "18 \t14    \t0.988286\t0.988286\t0.988286\n",
            "19 \t15    \t0.988286\t0.988286\t0.988286\n",
            "20 \t14    \t0.988286\t0.988286\t0.988286\n",
            "\n",
            "--- Resultados da Otimização do Modelo de Diabetes ---\n",
            "Melhores hiperparâmetros: n_estimators=161, max_depth=5\n",
            "Precisão de Validação Cruzada do melhor modelo: 0.9896\n",
            "\n",
            "Desempenho final do modelo otimizado:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        99\n",
            "           1       1.00      1.00      1.00        55\n",
            "\n",
            "    accuracy                           1.00       154\n",
            "   macro avg       1.00      1.00      1.00       154\n",
            "weighted avg       1.00      1.00      1.00       154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula para Otimização de Hiperparâmetros do Modelo de Estresse\n",
        "\n",
        "import random\n",
        "from deap import base, creator, tools, algorithms\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "\n",
        "# A função de aptidão já foi criada na célula anterior\n",
        "# creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "# creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "\n",
        "# Definir os hiperparâmetros que o algoritmo irá otimizar para o SVC\n",
        "toolbox.register(\"attr_C\", random.uniform, 0.1, 10.0)\n",
        "toolbox.register(\"attr_gamma\", random.uniform, 0.001, 1.0)\n",
        "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
        "                 (toolbox.attr_C, toolbox.attr_gamma), n=1)\n",
        "\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "# Definir a função de avaliação (fitness) para o modelo de estresse\n",
        "def evaluate_stress(individual):\n",
        "    C = individual[0]\n",
        "    gamma = individual[1]\n",
        "\n",
        "    model = SVC(C=C, gamma=gamma, probability=True, random_state=42)\n",
        "\n",
        "    try:\n",
        "        score = cross_val_score(model, X_stress, y_stress, cv=5, scoring='accuracy').mean()\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na avaliação: {e}\")\n",
        "        score = 0\n",
        "    return (score,)\n",
        "\n",
        "toolbox.register(\"evaluate\", evaluate_stress)\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)  # Crossover\n",
        "\n",
        "# Corrigido: Usar mutGaussian para valores de ponto flutuante\n",
        "# Os parâmetros são: mu (média), sigma (desvio padrão), e indpb (probabilidade de mutação por gene)\n",
        "toolbox.register(\"mutate\", tools.mutGaussian, mu=[0, 0], sigma=[1, 0.1], indpb=0.1)\n",
        "\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)  # Seleção\n",
        "\n",
        "# --- 2. Executar o Algoritmo Genético ---\n",
        "print(\"Iniciando a otimização dos hiperparâmetros do modelo de estresse...\")\n",
        "\n",
        "pop = toolbox.population(n=20)\n",
        "hof = tools.HallOfFame(1)\n",
        "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "stats.register(\"avg\", np.mean)\n",
        "stats.register(\"min\", np.min)\n",
        "stats.register(\"max\", np.max)\n",
        "\n",
        "algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=20, stats=stats, halloffame=hof, verbose=True)\n",
        "\n",
        "# --- 3. Exibir o Melhor Resultado ---\n",
        "print(\"\\n--- Resultados da Otimização do Modelo de Estresse ---\")\n",
        "best_individual_stress = hof[0]\n",
        "best_score_stress = best_individual_stress.fitness.values[0]\n",
        "\n",
        "print(f\"Melhores hiperparâmetros: C={best_individual_stress[0]:.4f}, gamma={best_individual_stress[1]:.4f}\")\n",
        "print(f\"Precisão de Validação Cruzada do melhor modelo: {best_score_stress:.4f}\")\n",
        "\n",
        "best_svm_stress = SVC(C=best_individual_stress[0], gamma=best_individual_stress[1], probability=True)\n",
        "best_svm_stress.fit(X_stress, y_stress)\n",
        "print(\"\\nDesempenho final do modelo otimizado:\")\n",
        "print(classification_report(y_stress, best_svm_stress.predict(X_stress)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYBfEbFq0gx0",
        "outputId": "bf7a2d4f-551f-4daa-9676-abb7deedd524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando a otimização dos hiperparâmetros do modelo de estresse...\n",
            "gen\tnevals\tavg    \tmin  \tmax  \n",
            "0  \t20    \t0.96575\t0.948\t0.983\n",
            "1  \t14    \t0.9708 \t0.881\t0.985\n",
            "2  \t9     \t0.97925\t0.926\t0.985\n",
            "3  \t17    \t0.9843 \t0.981\t0.986\n",
            "4  \t12    \t0.9847 \t0.982\t0.986\n",
            "5  \t9     \t0.98535\t0.985\t0.986\n",
            "6  \t9     \t0.98575\t0.985\t0.986\n",
            "7  \t12    \t0.986  \t0.986\t0.986\n",
            "8  \t14    \t0.98555\t0.982\t0.986\n",
            "9  \t13    \t0.98565\t0.981\t0.986\n",
            "10 \t12    \t0.9858 \t0.982\t0.986\n",
            "11 \t10    \t0.9857 \t0.982\t0.986\n",
            "12 \t8     \t0.986  \t0.986\t0.986\n",
            "13 \t14    \t0.98595\t0.985\t0.986\n",
            "14 \t7     \t0.986  \t0.986\t0.986\n",
            "15 \t13    \t0.986  \t0.986\t0.986\n",
            "16 \t12    \t0.9858 \t0.982\t0.986\n",
            "17 \t16    \t0.986  \t0.986\t0.986\n",
            "Erro na avaliação: \n",
            "All the 5 fits failed.\n",
            "It is very likely that your model is misconfigured.\n",
            "You can try to debug the error by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'gamma' parameter of SVC must be a str among {'scale', 'auto'} or a float in the range [0.0, inf). Got -0.04433265525941832 instead.\n",
            "\n",
            "18 \t12    \t0.9366 \t0    \t0.986\n",
            "19 \t14    \t0.9858 \t0.982\t0.986\n",
            "20 \t10    \t0.986  \t0.986\t0.986\n",
            "\n",
            "--- Resultados da Otimização do Modelo de Estresse ---\n",
            "Melhores hiperparâmetros: C=2.0031, gamma=0.0151\n",
            "Precisão de Validação Cruzada do melhor modelo: 0.9860\n",
            "\n",
            "Desempenho final do modelo otimizado:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       750\n",
            "           1       0.98      0.97      0.97       250\n",
            "\n",
            "    accuracy                           0.99      1000\n",
            "   macro avg       0.98      0.98      0.98      1000\n",
            "weighted avg       0.99      0.99      0.99      1000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}